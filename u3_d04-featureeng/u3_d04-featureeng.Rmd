---
title: "Feature Engineering"
subtitle: "Applications of Data Science"
author: "Giora Simchoni"
institute: "Stat. and OR Department, TAU"
date: "`r Sys.Date()`"
output_dir: "images"
output:
  xaringan::moon_reader:
    css: "../slides.css"
    seal: false
    chakra: "../libs/remark-latest.min.js"
    includes:
      in_header: "../header.html"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: inline
---

class: logo-slide

---

class: title-slide

## Feature Engineering

### Applications of Data Science - Class 15

### Giora Simchoni

#### `gsimchoni@gmail.com and add #dsapps in subject`

### Stat. and OR Department, TAU
### `r Sys.Date()`

---
```{r child = "../setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(glue)
```

class: section-slide

# What can you possibly teach us about Feature Engineering?

---

Our two previous modeling attempts, with [Modeling in the Tidyverse](https://dsapps-2020.github.io/Class_Slides/u1_d05-modeling/u1_d05-modeling.html) and in [The Trees](https://dsapps-2020.github.io/Class_Slides/u3_d01-trees/u3_d01-trees.html) where problematic.

- Using a "sinked" split, not using `set.seed()` - reproducible but wasteful
- "Lazy" feature engineering, not using the entire data, not creative
- No interactions
- Test once, on the same validation set, for everything
- Data "leakage" from training set to validation set (when imputing missing values)
- Sometimes tuning params, sometimes not
- No pre-processing of features, if at all by a hunch
- Not thinking about Multicollinearity where it hurts (regession)
- Almost no treatment of class imbalance in classification
- Chaotic feature selection

---

Reminder: We have two tasks, Regression and Classification:

1. Predict the income of an OKCupid user (from those who reported income)
2. Predict if an OKCupid user is a Cats or Dogs person, where:

```{r}
cats_categories <- c("has cats", "likes cats", "dislikes dogs and has cats",
                     "dislikes dogs and likes cats")
dogs_categories <- c("has dogs", "likes dogs", "has dogs and dislikes cats",
                     "likes dogs and dislikes cats")
```

And 80% of users are Dogs people, so we have class imbalance.

---

On our validation set we got...

- Regression Task

Model       | RMSE | R
------------|------|--
LM          | 0.35 | 0.5
LM-L2       | 0.35 | 0.5
LM-L1       | 0.35 | 0.5
CART        | 0.36 | 0.45
Bagging     | 0.37 | 0.44
RF          | 0.35 | 0.49
GBT-gbm     | 0.35 | 0.5
GBT-XGBOOST | 0.35 | 0.5

---

- Classification Task

Model     | AUC | Accuracy | Recall Dogs | Precision Dogs | Recall Cats | Precision Cats
----------|-----|----------|-------------|----------------|-------------|----------
GLM       | 0.74|  0.68    |  0.68       |  0.92          |  0.66       |  0.26
GLM-EN    | 0.74|  0.67    |  0.67       |  0.92          |  0.67       |  0.26
CART      | 0.67|  0.75    |  0.79       |  0.9           |  0.49       |  0.28
GBT+Cutoff| 0.74|  0.70    |  0.71       |  0.9           |  0.65       |  0.32

And we were not impressed.

---

class: section-slide

# Resampling/Cross-Validation

---

### Resampling done right

The main goal of resampling: No Surprises.

(By generating multiple versions of our data, and watching how our model behaves on unseen fresh data again. And again. And again.)

- Resampling is a key principle when developing a ML solution
- All ML practitioners are aware of the menace of overfitting
- But resampling should also be made for:
  - Feature engineering and transformation .font80percent[(should I use the Box-Cox or Yeo-Johnson transformation?)]
  - Feature selection .font80percent[(Should I use 2nd-order intearctions here?)]
  - Choosing imputation strategy .font80percent[(Simply use the median or regress?)]
  - Tuning parameters .font80percent[(100 or 500 trees?)]
  - Model selection .font80percent[(LM or MARS?)]
  
---

- A good resampling scheme will:
  - Have more than one train/valid/test samples!*
  - Be stratified (usually by dependent variable distribution)
  - Use a (paired/repeated/within) statistical test on resamples to reach a decision, or at least a proper plot
  - Avoid data "leakage" and not include the test set!
  - Encompass all steps in model building
  - Ideally (when data is Big) perform each step on a different part *of the training data*

.insight[
`r emo::ji("bulb")` &ast; How many resamples?

`-` The higher the number the lower the variance of performance metric

`-` The higher the number the less data used in each resample, the higher the bias of performance metric
]

---

### Ideally (yes, I know)

<img src = "images/resampling.png" style="width: 100%">

---

### And don't forget

Only once we decide on the final pre-processing, features, model and parameters, will we fit the model two more times:
  1. On the entire training data, then test on the testing data and get a realistic metric of performance
  2. On the *entire* data, right before deployment to production
  
---

### Many approaches to resampling

But two most common:

1. V-fold Cross Validation (+ optionally repeating n times)
2. Bootstrap Samples

---

#### V-fold Cross Validation

<img src = "images/cv_viz.png" style="width: 90%">

.font80percent[
[Applied Machine Learning Workshop at Rstudio-conf 2019 / Max Kuhn](https://github.com/topepo/rstudio-conf-2019)
]

---

#### Bootstrap Samples

<img src = "images/boot_viz.png" style="width: 90%">

.insight[
`r emo::ji("bulb")` What is the probability of entering a fold (at least once)?
]

---

class: section-slide

# Let's Start from the Very Beginning

---

### OkCupid from scratch

```{r}
okcupid <- read_csv("../data/okcupid.csv.zip")

cats_categories <- c("has cats", "likes cats", "dislikes dogs and has cats",
                     "dislikes dogs and likes cats")
dogs_categories <- c("has dogs", "likes dogs", "has dogs and dislikes cats",
                     "likes dogs and dislikes cats")

okcupid <- okcupid %>%
  mutate(pets = case_when(
           pets %in% cats_categories ~ "cats",
           pets %in% dogs_categories ~ "dogs",
           TRUE ~ NA_character_)) %>%
  drop_na(pets) %>%
  na_if(-1) %>%
  select(-last_online)

okcupid %>% count(pets)
```

Using `rsample::initial_split(okcupid, strata = pets)` would have been better, but if we do it now our results would not be comparabale.

```{r}
idx <- read_rds("../data/okcupid3_idx.rda")
train_idx <- idx$train_idx
valid_idx <- idx$valid_idx
test_idx <- idx$test_idx

okcupid_train <- okcupid[train_idx, ]
okcupid_valid <- okcupid[valid_idx, ]
okcupid_test <- okcupid[test_idx, ]
```

And let us bind `okcupid_train` and `okcupid_valid` together because we are going to use resampling anyway:

```{r}
okcupid_train <- bind_rows(okcupid_train, okcupid_valid)

glue("train no. of rows: {nrow(okcupid_train)}
     test no. of rows: {nrow(okcupid_test)}")
```

See that the class balance is more or less the same:

```{r}
okcupid_train %>% count(pets) %>% mutate(pct = n / sum(n))

okcupid_test %>% count(pets) %>% mutate(pct = n / sum(n))
```

Good enough .font80percent[(we could also drop a few cat people at random if they're too much)].

We stash our test data aside, kiss it good bye, we shall not see it again before the final assessment of our model.

Manager mentions casually: oh, and by the way, this model thingy of yours. Yeah, we need it to run in, like 10 milliseconds per user. Marketing team needs that, don't ask me why, and we can't have the users wait.

You: penalized logistic regression it is `r emo::ji("smirking face")`

No one mentioned cats/dogs recall/precision to be of any particular importance, so we decide to maximize AUC and take care of cutoff later.

We explore the training data (skipping here at least a couple of hours in which we actually explore the data, I'm assuming we already know quite a bit!):

```{r}
glimpse(okcupid_train)
```

```{r}
library(naniar)

vis_miss(okcupid_train %>%
           sample_frac(0.2) %>%
           select(-starts_with("essay")))
```

A few questions and answers:

Q: What type of variables do we have?
A: Numeric: age, height income; Text: essays; Categorical: all others

Q: Can our model(s) handle missing values?
A: Probably gonna use `glmnet` so: NO.

Q: Are missing values a serious issue here?
A: Oh yes. `income` 80+% missing, `offspring` 50+% missing. Gonna have to take care of it.

Q: Categorical variables with many levels?
A: Oh yes. `speaks` has over 2K. And there are those `essay`s.

Q: Numeric variables skewed?
A: Income, but all you need is log.

Q: Classes imbalance scenario?
A: Pretty imbalanced, 5 dogs people for every 1 cat person. Gonna have to take care of it.

---

Strategy: Divide training data into 5 samples for 5 main decision/steps/tunings:

1. Missing data imputation
2. Class imbalance treatment
3. Feature Engineering and Selection
4. Model Tuning
5. Cutoff choice

.insight[
`r emo::ji("bulb")` We assume these decisions are additive or independent of each other. Does it have to be and what can we do if we suspect not? (Remember we are a Statisticians!)
]

Looking at our strategy, we decide the 12.7K observations need not split evenly between steps.

- Cutoff choice is "peanuts" compared to the other decisions, let's decide in advance that at this stage we would fit the chosen model on ~12K previously seen observations and choose a cutoff by looking at the remaining ~700 observations
- Missing data imputation and class imbalance steps will each be given 2K observations
- Model tuning 3K observations
- Text and Interactions Feature engineering and selection 5K observations
- Total: 12,729 training observations

---

We wish to make sure our samples are stratified by `pets`, so we'll use `initial_split()` in stages:

```{r, message=FALSE, warning=FALSE}
library(tidymodels)

set.seed(42)
ok_cutoff_split <- initial_split(okcupid_train,
                                 strata = pets, prop = (729 - 1)/12729)
ok_tr_cutoff <- training(ok_cutoff_split)
ok_train <- testing(ok_cutoff_split)

set.seed(42)
ok_missing_split <- initial_split(ok_train,
                                  strata = pets, prop = (2000 - 1)/12000)
ok_tr_missing <- training(ok_missing_split)
ok_train <- testing(ok_missing_split)

set.seed(42)
ok_imbalance_split <- initial_split(ok_train,
                                  strata = pets, prop = (2000 - 1)/10000)
ok_tr_imbalance <- training(ok_imbalance_split)
ok_train <- testing(ok_imbalance_split)

set.seed(42)
ok_tuning_split <- initial_split(ok_train,
                                  strata = pets, prop = (3000 - 1)/8000)
ok_tr_tuning <- training(ok_tuning_split)
ok_tr_eng <- testing(ok_tuning_split)
```

```{r, echo=FALSE}
tibble(name = c("missing", "imbalance", "engineering", "tuning", "cutoff", "test"),
       df = list(ok_tr_missing, ok_tr_imbalance, ok_tr_eng, ok_tr_tuning, ok_tr_cutoff, okcupid_test)) %>%
  mutate(n_rows = map_dbl(df, nrow),
         cats_rate = map_dbl(df, ~mean(.x$pets == "cats")))
```

---

### Missing Data

.font80percent[We could fill an entire semester on this subject!]

- What causes a missing datum?
  - Survey data
  - Merging data sources
  - Failure of measurement

- What is the missing data mechanism?
  - See [Little & Rubin (2019)](https://www.amazon.com/Statistical-Analysis-Missing-Probability-Statistics-ebook/dp/B07Q25CNSD/ref=sr_1_1?crid=2P6ERH22YRKUL&dchild=1&keywords=statistical+analysis+with+missing+data&qid=1587103544&s=books&sprefix=statistical+ana%2Cstripbooks-intl-ship%2C286&sr=1-1) seminal work
  - MCAR: "on some days the weighing scale batteries drained and we couldn't take the mice weight"
  - MAR: "on the 2024 elections poll a massive Facebook campaign called all women to refuse to cooperate with the Seker-Sheker company due to allegations of sexual harassment by the company's head Dani Marom"
  - MNAR: "some of the drug addicts under study missed the final few meetings in the treatment group and their data were discarded"
  
.insight[
`r emo::ji("bulb")` How would you asses the missing data mechanism in your dataset?
]

---

Exploring percent missingness:

```{r}
gg_miss_var(ok_tr_missing %>%
              select(-starts_with("essay")),
            show_pct = TRUE)
```

---

Exploring percent missingness by a predictor:

```{r, warning=FALSE}
gg_miss_var(ok_tr_missing %>%
              select(-starts_with("essay")),
            facet = sex, show_pct = TRUE)
```

---

Exploring missingness between a predictor and the response (categorical) variable:

```{r}
ok_tr_missing %>%
    mutate(income_missing = is.na(income)) %>%
    count(income_missing, pets) %>%
  pivot_wider(id_cols = pets,
              names_from = income_missing,
              values_from = n) %>%
  mutate(pct_missing = `TRUE` / (`TRUE` + `FALSE`))
```

---

But we can do better:

```{r}
pct_missing <- function(predictor, pet) {
  ok_tr_missing %>%
    filter(pets == pet) %>%
    select(all_of(predictor)) %>%
    is.na() %>%
    mean()
}
pct_missing_gap <- function(predictor) {
  pct_missing(predictor, "dogs") - pct_missing(predictor, "cats")
}
predictors <- colnames(ok_tr_missing %>% select(-pets))

tibble(predictor = predictors,
       pct_miss_gap = map_dbl(predictor, pct_missing_gap),
       gap_positive = pct_miss_gap >= 0) %>%
  mutate(predictor = fct_reorder(predictor, pct_miss_gap)) %>%
  ggplot(aes(pct_miss_gap, predictor, fill = gap_positive)) +
  geom_col() +
  geom_vline(xintercept = 0) +
  guides(fill = FALSE) +
  labs(x = NULL, y = NULL, title = "%Missing: Dogs - Cats") +
  scale_x_continuous(labels = percent_format()) +
  theme_light()
```

---

Exploring missingness between two (categorical) predictors:

```{r}
library(ggmosaic)

ok_tr_missing %>%
  mutate(body_type_missing = is.na(body_type)) %>%
  ggplot() +
  geom_mosaic(aes(x = product(body_type_missing, status),
                  fill = body_type_missing)) +
  labs(x = NULL, y = NULL) +
  theme_light()
```

```{r}
ok_tr_missing %>%
    mutate(body_type_missing = is.na(body_type)) %>%
    count(body_type_missing, status) %>%
  pivot_wider(id_cols = status,
              names_from = body_type_missing,
              values_from = n) %>%
  mutate(pct_missing = `TRUE` / (`TRUE` + `FALSE`))
```

```{r}
ok_tr_missing %>%
    mutate(body_type_missing = is.na(body_type),
           drugs_missing = is.na(drugs)) %>%
    count(body_type_missing, drugs_missing) %>%
  pivot_wider(id_cols = drugs_missing,
              names_from = body_type_missing,
              values_from = n) %>%
  mutate(pct_missing = `TRUE` / (`TRUE` + `FALSE`))
```

---

But we can do better with a co-occurrence plot or a heatmap:

```{r}
ok_tr_missing %>%
  count(drugs, body_type) %>%
  ggplot(aes(drugs, body_type)) +
  geom_point(aes(size = n)) +
  theme_light()
```

---

Exploring missingness between numerical and categorical predictors:

```{r}
ok_tr_missing %>%
  mutate(bodytype_missing = is.na(body_type)) %>%
  ggplot(aes(bodytype_missing, age)) +
  geom_violin() +
  facet_wrap(. ~ sex) +
  theme_light()
```

---

Exploring missingness between two numerical predictors (borrowing data):

```{r}
ggplot(airquality, aes(Ozone, Solar.R)) +
  geom_miss_point() +
  theme_light()
```

---

When the data is large you could perform PCA on the binary missing/non-missing matrix:

```{r}
binary_mat <- ok_tr_missing %>%
  select(-pets) %>%
  mutate_all(is.na)

prcomp(binary_mat) %>%
  pluck("rotation") %>%
  as_tibble() %>%
  select(PC1, PC2) %>%
  bind_cols(
    tibble(
      predictor = colnames(binary_mat),
      pct_missing = binary_mat %>% colSums() / nrow(ok_tr_missing) 
    )
  ) %>%
  mutate(label = ifelse(PC1 < -0.3 | PC2 > 0.3, predictor, "")) %>%
  ggplot(aes(PC1, PC2)) +
  geom_point(aes(size = pct_missing), color = "lightblue", alpha = 0.5) +
  ggrepel::geom_text_repel(aes(label = label)) +
  theme_light()
```

---

### Definitely not in MCAR land

- Keep the data missing, drop it all or impute values?
  - Very much depends on the mechanism of missing data
  - "Drop it all" only if you're "data rich" and assume MCAR
  - Keep or impute: can your model handle missing values?
  - "It's not a bug, it's a feature!": a new category or an additional variable
  - Use resampling to test the best strategy!

- How to impute?
  - Very much depends on the mechanism of missing data
  - Mean/median value if MCAR
  - kNN imputation
  - Iterative Regression/Classification algos (EM algorithm)
  - Use resampling to test the best strategy!

- What do you do with missing values in the response variable?
  - Semi-supervised Learning
  - Active Learning
  
---

Let's choose between 2 x 3 x 3 = 18 strategies:

1. Missing categorical features
  - adding an "unknown" category
  - imputing the most common category
2. The `income` feature:
  - Dropping it (it is 80% missing!!)
  - Log transofrmation, imputing the mean
  - Log transformation, kNN Imputation
3. The `essay` features:
  - Dropping  them
  - Adding `essay` length where a missing `essay` has length 0
  - Adding `essay` length where a missing `essay` has length 0 and adding "is_missing" feature to each `essay`

---

```{r}
ok_tr_missing2 <- ok_tr_missing %>%
  select(-starts_with("essay")) %>%
  bind_cols(
    ok_tr_missing %>%
      transmute_at(vars(essay0:essay9),
            list("len" = ~ifelse(is.na(.x), 0, str_length(.x))))
  ) %>%
  bind_cols(
    ok_tr_missing %>%
      transmute_at(vars(essay0:essay9),
            list("isna" = ~ifelse(is.na(.x), 1, 0)))
  ) %>%
  rename_at(vars(contains("_len")),
            list(~paste("len", gsub("_len", "", .),
                        sep = "_") ) ) %>%
  rename_at(vars(contains("_isna")),
            list(~paste("isna", gsub("_isna", "", .),
                        sep = "_") ) ) %>%
  mutate_if(is.character, as.factor)
```

---
Defining recipes (without `prep()`!):

```{r}
rec_miss_unk_none_none <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(income, contains("essay"), new_role = "discarded") %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_none_none <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(income, contains("essay"), new_role = "discarded") %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_unk_mean_none <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(contains("essay"), new_role = "discarded") %>%
  step_log(income, offset = 1) %>%
  step_meanimpute(income) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_mean_none <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(contains("essay"), new_role = "discarded") %>%
  step_log(income, offset = 1) %>%
  step_meanimpute(income) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)
```

---

Defining resamples:

```{r}
set.seed(42)
cv_splits_missing <- vfold_cv(ok_tr_missing2, v = 10, strata = pets)

cv_splits_missing
```

---

Applying recipes to all models and fitting models

```{r}
cv_splits_missing$rec_miss_unk_none_none <- map(
  cv_splits_missing$splits, prepper, recipe = rec_miss_unk_none_none)
cv_splits_missing$rec_miss_mode_none_none <- map(
  cv_splits_missing$splits, prepper, recipe = rec_miss_mode_none_none)

map_dbl(cv_splits_missing$rec_miss_unk_none_none, ~nrow(.$term_info))
```

```{r}
cv_splits_missing$rec_miss_unk_none_none[[1]]$term_info %>%
  filter(str_detect(variable, "speaks"))
```

---

Defining the model:

```{r}
mod_lr <- logistic_reg() %>%
  set_engine("glmnet")
```

Fitting the model:

```{r}
fit_lr <- function(rec_obj) 
  fit(mod_lr, pets ~ .,
      data = juice(rec_obj, all_predictors(), all_outcomes()))

cv_splits_missing$mod_lr_unk <- map(
  cv_splits_missing$rec_miss_unk_none_none, fit_lr)
cv_splits_missing$mod_lr_mode <- map(
  cv_splits_missing$rec_miss_mode_none_none, fit_lr)
```

---

Predicting on assessment data:

```{r}
pred_lr <- function(split_obj, rec_obj, model_obj) {
  mod_data <- bake(rec_obj,
                   new_data = assessment(split_obj),
                   all_predictors(), all_outcomes()) 
  
  out <- mod_data %>% select(pets)
  out$predicted <- predict(model_obj, mod_data, type = "prob",
                           penalty = 0.0001)$.pred_cats
  out
}

cv_splits_missing$pred_unk <- 
  pmap(
    lst(
      split_obj = cv_splits_missing$splits, 
      rec_obj = cv_splits_missing$rec_miss_unk_none_none, 
      model_obj = cv_splits_missing$mod_lr_unk
    ),
    pred_lr
  )
cv_splits_missing$pred_mode <- 
  pmap(
    lst(
      split_obj = cv_splits_missing$splits, 
      rec_obj = cv_splits_missing$rec_miss_mode_none_none, 
      model_obj = cv_splits_missing$mod_lr_mode
    ),
    pred_lr
  )
```

```{r}
cv_splits_missing$step_unknown <- map_dfr(
  cv_splits_missing$pred_unk, roc_auc, pets, predicted)$.estimate
cv_splits_missing$step_mode <- map_dfr(
  cv_splits_missing$pred_mode, roc_auc, pets, predicted)$.estimate
```


```{r}
cv_splits_missing %>%
  select(id, step_unknown, step_mode) %>%
  pivot_longer(cols = c(step_unknown, step_mode),
               names_to = "recipe", values_to = "auc") %>%
  ggplot(aes(recipe, auc, group = id, color = id)) +
  geom_line() +
  geom_point() +
  guides(color = FALSE) +
  theme_light()
```

```{r}
t.test(cv_splits_missing$step_unknown,
       cv_splits_missing$step_mode, paired = TRUE)
```

But we have multiple recipes, and we don't need to keep all data just final AUC for each recipe:

```{r}
lst_recs <- list("unknown_none" = rec_miss_unk_none_none,
                 "mode_none" = rec_miss_mode_none_none,
                 "unknown_mean" = rec_miss_unk_mean_none,
                 "mode_mean" = rec_miss_mode_mean_none)

train_recipe <- function(rec, rec_name, splits) {
  splits_prepped <- map(splits, prepper, recipe = rec)
  splits_fit <- map(splits_prepped, fit_lr)
  splits_pred <- pmap(
    lst(
      split_obj = splits, 
      rec_obj = splits_prepped, 
      model_obj = splits_fit
    ),
    pred_lr
  )
  res <- map_dfr(splits_pred, roc_auc, pets, predicted)$.estimate
  names(res) <- rec_name
  res
}
```

```{r}
cv_splits_missing <- cv_splits_missing %>%
  bind_cols(
    map2_dfc(lst_recs, names(lst_recs), train_recipe,
             splits = cv_splits_missing$splits)
  )
```

```{r}
cv_res_missing <- cv_splits_missing %>%
    pivot_longer(cols = names(lst_recs),
                 names_to = "recipe", values_to = "AUC") %>%
  select(id, recipe, AUC) %>%
  separate(recipe, c("categorical", "income"))
```

Repeated measures ANOVA:

```{r}
aov_missing <- aov(
  AUC ~ factor(categorical) * factor(income) + Error(factor(id)),
  data = cv_res_missing)
print(summary(aov_missing))
with(cv_res_missing, interaction.plot(categorical, income, AUC))
```

Or you can look at the numbers...

```{r}
cv_res_missing %>%
  ggplot(aes(income, AUC, group = id, color = id)) +
    geom_line() +
    geom_point() +
    guides(color = FALSE) + facet_wrap(. ~ categorical) +
    theme_light()
```

```{r}
rec_miss_unk_knn_none <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(contains("essay"), new_role = "discarded") %>%
  step_log(income, offset = 1) %>%
  step_knnimpute(income,
                 impute_with = imp_vars(
                   sex, age, starts_with("job"),
                   starts_with("education"))) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_knn_none <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(contains("essay"), new_role = "discarded") %>%
  step_log(income, offset = 1) %>%
  step_knnimpute(income,
                 impute_with = imp_vars(
                   sex, age, height, starts_with("job"),
                   starts_with("education"))) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_unk_none_len <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(income, starts_with("isna"), new_role = "discarded") %>%
  step_log(starts_with("len"), offset = 1) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_none_len <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(income, starts_with("isna"), new_role = "discarded") %>%
  step_log(starts_with("len"), offset = 1) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_unk_mean_len <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(starts_with("isna"), new_role = "discarded") %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_meanimpute(income) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_mean_len <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(starts_with("isna"), new_role = "discarded") %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_meanimpute(income) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_unk_knn_len <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(starts_with("isna"), new_role = "discarded") %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_knnimpute(income,
                 impute_with = imp_vars(
                   sex, age, height, starts_with("job"),
                   starts_with("education"))) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_knn_len <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(starts_with("isna"), new_role = "discarded") %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_knnimpute(income,
                 impute_with = imp_vars(
                   sex, age, height, starts_with("job"),
                   starts_with("education"))) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

###

rec_miss_unk_none_isna <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(income, new_role = "discarded") %>%
  step_log(starts_with("len"), offset = 1) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_none_isna <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  update_role(income, new_role = "discarded") %>%
  step_log(starts_with("len"), offset = 1) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_unk_mean_isna <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_meanimpute(income) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_mean_isna <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_meanimpute(income) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_unk_knn_isna <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_knnimpute(income,
                 impute_with = imp_vars(
                   sex, age, height, starts_with("job"),
                   starts_with("education"))) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_unknown(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)

rec_miss_mode_knn_isna <- recipe(pets ~ ., data = ok_tr_missing2) %>%
  step_log(income, starts_with("len"), offset = 1) %>%
  step_knnimpute(income,
                 impute_with = imp_vars(
                   sex, age, height, starts_with("job"),
                   starts_with("education"))) %>%
  step_normalize(all_numeric(), -has_role("discarded")) %>%
  step_other(all_nominal(), -has_role("discarded"), other = "other1") %>%
  step_novel(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_modeimpute(all_nominal(), -has_role("discarded"), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(),
             -has_role("discarded"), one_hot = FALSE)
```

```{r}
lst_recs <- list("unknown_none_none" = rec_miss_unk_none_none,
                 "mode_none_none" = rec_miss_mode_none_none,
                 "unknown_mean_none" = rec_miss_unk_mean_none,
                 "mode_mean_none" = rec_miss_mode_mean_none,
                 "unknown_knn_none" = rec_miss_unk_knn_none,
                 "mode_knn_none" = rec_miss_mode_knn_none,
                 "unknown_none_len" = rec_miss_unk_none_len,
                 "mode_none_len" = rec_miss_mode_none_len,
                 "unknown_mean_len" = rec_miss_unk_mean_len,
                 "mode_mean_len" = rec_miss_mode_mean_len,
                 "unknown_knn_len" = rec_miss_unk_knn_len,
                 "mode_knn_len" = rec_miss_mode_knn_len,
                 "unknown_none_isna" = rec_miss_unk_none_isna,
                 "mode_none_isna" = rec_miss_mode_none_isna,
                 "unknown_mean_isna" = rec_miss_unk_mean_isna,
                 "mode_mean_isna" = rec_miss_mode_mean_isna,
                 "unknown_knn_isna" = rec_miss_unk_knn_isna,
                 "mode_knn_isna" = rec_miss_mode_knn_isna
                 )
```

```{r}
set.seed(42)
cv_splits_missing <- vfold_cv(ok_tr_missing2, v = 10, strata = pets)
```

```{r}
cv_splits_missing <- cv_splits_missing %>%
  bind_cols(
    map2_dfc(lst_recs, names(lst_recs), train_recipe,
             splits = cv_splits_missing$splits)
  )
```

```{r}
cv_res_missing <- cv_splits_missing %>%
    pivot_longer(cols = names(lst_recs),
                 names_to = "recipe", values_to = "AUC") %>%
  select(id, recipe, AUC) %>%
  separate(recipe, c("categorical", "income", "essay"))
```

Repeated measures ANOVA:

```{r}
aov_missing <- aov(
  AUC ~ factor(categorical) * factor(income) + factor(essay) + Error(factor(id)),
  data = cv_res_missing)
print(summary(aov_missing))
# with(cv_res_missing, interaction.plot(categorical, income, essay, AUC))
```

Or you can look at the numbers...

```{r}
cv_res_missing %>%
  group_by(id, income, essay) %>%
  summarise(AUC = mean(AUC)) %>%
  ggplot(aes(income, AUC, group = id, color = id)) +
    geom_line() +
    geom_point() +
    guides(color = FALSE) + facet_wrap(. ~ essay) +
    theme_light()
```

```{r}
cv_res_missing %>%
  group_by(categorical, income, essay) %>%
  summarise(AUC = mean(AUC)) %>%
  arrange(-AUC)
```

