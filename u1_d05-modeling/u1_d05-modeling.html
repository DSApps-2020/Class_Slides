<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Modeling in the Tidyverse</title>
    <meta charset="utf-8" />
    <meta name="author" content="Giora Simchoni" />
    <meta name="date" content="2020-03-12" />
    <head>
      <link rel="icon" href="../DSApps_logo.jpg" type="image/jpg"> 
      <link rel="shortcut icon" href="../DSApps_logo.jpg" type="image/jpg">
    </head>
    <link rel="stylesheet" href="..\slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: logo-slide

---

class: title-slide

## Modeling in the Tidyverse

### Applications of Data Science - Class 5

### Giora Simchoni

#### `gsimchoni@gmail.com and add #dsapps in subject`

### Stat. and OR Department, TAU
### 2020-03-12

---



layout: true

&lt;div class="my-footer"&gt;
  &lt;span&gt;
    &lt;a href="https://dsapps-2020.github.io/Class_Slides/" target="_blank"&gt;Applications of Data Science
    &lt;/a&gt;
  &lt;/span&gt;
&lt;/div&gt;

---



class: section-slide

# The Problem

---

### Inconsistency, Inextensibility


```r
n &lt;- 10000
x1 &lt;- runif(n)
x2 &lt;- runif(n)
t &lt;- 1 + 2 * x1 + 3 * x2
y &lt;- rbinom(n, 1, 1 / (1 + exp(-t)))
```


```r
glm(y ~ x1 + x2, family = "binomial")
```


```r
glmnet(as.matrix(cbind(x1, x2)), as.factor(y), family = "binomial")
```


```r
randomForest(as.factor(y) ~ x1 + x2)
```



```r
gbm(y ~ x1 + x2, data = data.frame(x1 = x1, x2 = x2, y = y))
```

😱

---

### Compare this with `sklearn`


```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier,
  GradientBoostingClassifier

LogisticRegression(penalty='none').fit(X, y)

LogisticRegression(penalty='l2', C=0.001).fit(X, y)

RandomForestClassifier(n_estimators=100).fit(X, y)

GradientBoostingClassifier(n_estimators=100).fit(X, y)
```

---

class: section-slide

# Detour: A Regression Problem

---

### IPF-Lifts: Predicting Bench Lifting

- Dataset was published as part of the [TidyTuesday](https://github.com/rfordatascience/tidytuesday) intiative
- Comes from [Open Powerlifting](https://www.openpowerlifting.org/data)
- [Wikipedia](https://en.wikipedia.org/wiki/Powerlifting): Powerlifting is a strength sport that consists of three attempts at maximal weight on three lifts: squat, bench press, and deadlift

&lt;img src="images/pl_bench.jpg" style="width: 70%" /&gt;

---

The raw data has over 40K rows: for each athlete, for each event, stats about athlete gender, age and weight, and the maximal weight lifted in the 3 types of Powerlifting.

We will be predicting `best3bench_kg` based on a few predictors, no missing values:


```r
library(lubridate)

ipf_lifts &lt;- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-08/ipf_lifts.csv")

ipf_lifts &lt;- ipf_lifts %&gt;%
  drop_na(best3bench_kg, age) %&gt;%
  filter(between(age, 18, 100), best3bench_kg &gt; 0, equipment != "Wraps") %&gt;%
  select(sex, event, equipment, age, division, bodyweight_kg, best3bench_kg, date, meet_name) %&gt;%
  drop_na() %&gt;%
  mutate(year = year(date), month = month(date),
         dayofweek = wday(date)) %&gt;%
  select(-date) %&gt;%
  mutate_if(is.character, as.factor)

dim(ipf_lifts)
```

```
## [1] 32047    11
```

---


```r
glimpse(ipf_lifts)
```

```
## Observations: 32,047
## Variables: 11
## $ sex           &lt;fct&gt; F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...
## $ event         &lt;fct&gt; SBD, SBD, SBD, SBD, SBD, SBD, SBD, SBD, SBD, SBD...
## $ equipment     &lt;fct&gt; Single-ply, Single-ply, Single-ply, Single-ply, ...
## $ age           &lt;dbl&gt; 33.5, 34.5, 23.5, 27.5, 37.5, 25.5, 33.5, 26.0, ...
## $ division      &lt;fct&gt; Open, Open, Open, Open, Open, Open, Open, Open, ...
## $ bodyweight_kg &lt;dbl&gt; 44, 44, 44, 44, 44, 44, 48, 48, 48, 48, 48, 48, ...
## $ best3bench_kg &lt;dbl&gt; 60.0, 62.5, 62.5, 60.0, 65.0, 45.0, 62.5, 77.5, ...
## $ meet_name     &lt;fct&gt; World Powerlifting Championships, World Powerlif...
## $ year          &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1989, 1989, ...
## $ month         &lt;dbl&gt; 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, ...
## $ dayofweek     &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...
```

---

See the dependent variable distribution:


```r
ggplot(ipf_lifts, aes(best3bench_kg)) +
  geom_histogram(fill = "red", alpha = 0.5) +
  theme_classic()
```

&lt;img src="images/Bench-Hist-1.png" width="100%" /&gt;

---

See it vs. say age, facetted by equipment:


```r
ggplot(ipf_lifts, aes(age, best3bench_kg)) +
  geom_point(color = "red", alpha = 0.5) +
  facet_wrap(~ equipment) +
  theme_classic()
```

&lt;img src="images/Bench-Age-Equipment-1.png" width="100%" /&gt;

---

See it vs. year, by gender:


```r
ggplot(ipf_lifts, aes(factor(year), best3bench_kg, fill = sex)) +
  geom_boxplot(outlier.alpha = 0.5) +
  labs(fill = "", x = "", y = "") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

&lt;img src="images/Bench-Year-Gender-1.png" width="100%" /&gt;

---

Maybe add `\(age^2\)` and `\(year^2\)` to make Linear Regression's life easier?


```r
ipf_lifts &lt;- ipf_lifts %&gt;%
  mutate(age2 = age ^ 2, year2 = year ^2)
```

---

class: section-slide

# End of Detour

---

# WARNING

.warning[
💡 What you're about to see is not a good modeling/prediction flow. This is just an intro to tidy modeling. Some of the issues with how things are done here will be raised, some will have to wait till later in the course.
]
---

class: section-slide

# The Present Solution: `caret`

---

### Split Data


```r
library(caret)

train_idx &lt;- createDataPartition(ipf_lifts$best3bench_kg,
                                 p = 0.6, list = FALSE)

ipf_tr &lt;- ipf_lifts[train_idx, ]
ipf_te &lt;- ipf_lifts[-train_idx, ]

library(glue)
glue("train no. of rows: {nrow(ipf_tr)}
     test no. of rows: {nrow(ipf_te)}")
```

```
## train no. of rows: 19230
## test no. of rows: 12817
```

Here you might consider some preprocessing.

`caret` has some nice documentation [here](https://topepo.github.io/caret/index.html).

---

### Tuning and Modeling

Define general methodology, e.g. 10-fold Cross-Validation:


```r
fit_control &lt;- trainControl(method = "cv", number = 5)

ridge_grid &lt;- expand.grid(alpha=0, lambda = 10^seq(-3, 1, length = 50))
lasso_grid &lt;- expand.grid(alpha=1, lambda = 10^seq(-3, 1, length = 50))
rf_grid &lt;- expand.grid(splitrule = "variance",
                       min.node.size = seq(10, 30, 10),
                       mtry = seq(2, 10, 2))

mod_ridge &lt;- train(best3bench_kg ~ ., data = ipf_tr, method = "glmnet",
                trControl = fit_control, tuneGrid = ridge_grid,
                metric = "RMSE")

mod_lasso &lt;- train(best3bench_kg ~ ., data = ipf_tr, method = "glmnet",
                trControl = fit_control, tuneGrid = lasso_grid,
                metric = "RMSE")

mod_rf &lt;- train(best3bench_kg ~ ., data = ipf_tr, method = "ranger",
                trControl = fit_control, tuneGrid = rf_grid,
                num.trees = 50, metric = "RMSE")
```

---

### Evaluating Models


```r
mod_ridge
```

```
## glmnet 
## 
## 19230 samples
##    12 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 15385, 15385, 15383, 15383, 15384 
## Resampling results across tuning parameters:
## 
##   lambda        RMSE      Rsquared   MAE     
##    0.001000000  26.82721  0.8110942  20.47454
##    0.001206793  26.82721  0.8110942  20.47454
##    0.001456348  26.82721  0.8110942  20.47454
##    0.001757511  26.82721  0.8110942  20.47454
##    0.002120951  26.82721  0.8110942  20.47454
##    0.002559548  26.82721  0.8110942  20.47454
##    0.003088844  26.82721  0.8110942  20.47454
##    0.003727594  26.82721  0.8110942  20.47454
##    0.004498433  26.82721  0.8110942  20.47454
##    0.005428675  26.82721  0.8110942  20.47454
##    0.006551286  26.82721  0.8110942  20.47454
##    0.007906043  26.82721  0.8110942  20.47454
##    0.009540955  26.82721  0.8110942  20.47454
##    0.011513954  26.82721  0.8110942  20.47454
##    0.013894955  26.82721  0.8110942  20.47454
##    0.016768329  26.82721  0.8110942  20.47454
##    0.020235896  26.82721  0.8110942  20.47454
##    0.024420531  26.82721  0.8110942  20.47454
##    0.029470517  26.82721  0.8110942  20.47454
##    0.035564803  26.82721  0.8110942  20.47454
##    0.042919343  26.82721  0.8110942  20.47454
##    0.051794747  26.82721  0.8110942  20.47454
##    0.062505519  26.82721  0.8110942  20.47454
##    0.075431201  26.82721  0.8110942  20.47454
##    0.091029818  26.82721  0.8110942  20.47454
##    0.109854114  26.82721  0.8110942  20.47454
##    0.132571137  26.82721  0.8110942  20.47454
##    0.159985872  26.82721  0.8110942  20.47454
##    0.193069773  26.82721  0.8110942  20.47454
##    0.232995181  26.82721  0.8110942  20.47454
##    0.281176870  26.82721  0.8110942  20.47454
##    0.339322177  26.82721  0.8110942  20.47454
##    0.409491506  26.82721  0.8110942  20.47454
##    0.494171336  26.82721  0.8110942  20.47454
##    0.596362332  26.82721  0.8110942  20.47454
##    0.719685673  26.82721  0.8110942  20.47454
##    0.868511374  26.82721  0.8110942  20.47454
##    1.048113134  26.82721  0.8110942  20.47454
##    1.264855217  26.82721  0.8110942  20.47454
##    1.526417967  26.82721  0.8110942  20.47454
##    1.842069969  26.82721  0.8110942  20.47454
##    2.222996483  26.82721  0.8110942  20.47454
##    2.682695795  26.82721  0.8110942  20.47454
##    3.237457543  26.82721  0.8110942  20.47454
##    3.906939937  26.82721  0.8110942  20.47454
##    4.714866363  26.86235  0.8109050  20.49983
##    5.689866029  26.95841  0.8104330  20.56959
##    6.866488450  27.08258  0.8098970  20.66212
##    8.286427729  27.24376  0.8092847  20.78519
##   10.000000000  27.45296  0.8085845  20.95006
## 
## Tuning parameter 'alpha' was held constant at a value of 0
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were alpha = 0 and lambda = 3.90694.
```

---


```r
mod_lasso
```

```
## glmnet 
## 
## 19230 samples
##    12 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 15385, 15383, 15384, 15385, 15383 
## Resampling results across tuning parameters:
## 
##   lambda        RMSE      Rsquared   MAE     
##    0.001000000  26.40433  0.8151910  20.18166
##    0.001206793  26.40433  0.8151910  20.18166
##    0.001456348  26.40433  0.8151910  20.18166
##    0.001757511  26.40433  0.8151910  20.18166
##    0.002120951  26.40433  0.8151910  20.18166
##    0.002559548  26.40433  0.8151910  20.18166
##    0.003088844  26.40433  0.8151910  20.18166
##    0.003727594  26.40433  0.8151910  20.18166
##    0.004498433  26.40433  0.8151910  20.18166
##    0.005428675  26.40433  0.8151910  20.18166
##    0.006551286  26.40433  0.8151910  20.18166
##    0.007906043  26.40433  0.8151910  20.18166
##    0.009540955  26.40433  0.8151910  20.18166
##    0.011513954  26.40433  0.8151910  20.18166
##    0.013894955  26.40433  0.8151910  20.18166
##    0.016768329  26.40433  0.8151910  20.18166
##    0.020235896  26.40467  0.8151861  20.18205
##    0.024420531  26.40776  0.8151427  20.18468
##    0.029470517  26.41418  0.8150537  20.18962
##    0.035564803  26.42239  0.8149402  20.19522
##    0.042919343  26.43007  0.8148345  20.20001
##    0.051794747  26.43878  0.8147151  20.20507
##    0.062505519  26.45163  0.8145385  20.21328
##    0.075431201  26.46862  0.8143053  20.22448
##    0.091029818  26.49105  0.8139969  20.23970
##    0.109854114  26.52632  0.8135089  20.26470
##    0.132571137  26.57072  0.8128943  20.29749
##    0.159985872  26.62809  0.8120970  20.33911
##    0.193069773  26.65289  0.8117653  20.35572
##    0.232995181  26.66638  0.8116046  20.36254
##    0.281176870  26.68099  0.8114399  20.36935
##    0.339322177  26.70137  0.8112113  20.38026
##    0.409491506  26.73095  0.8108769  20.39856
##    0.494171336  26.77096  0.8104274  20.42346
##    0.596362332  26.82260  0.8098608  20.45597
##    0.719685673  26.89236  0.8091014  20.49872
##    0.868511374  26.97884  0.8081928  20.55127
##    1.048113134  27.09073  0.8070486  20.62235
##    1.264855217  27.24323  0.8054894  20.72282
##    1.526417967  27.45778  0.8032459  20.86817
##    1.842069969  27.73399  0.8003877  21.05898
##    2.222996483  28.10645  0.7964555  21.32355
##    2.682695795  28.58676  0.7913456  21.67182
##    3.237457543  29.21562  0.7844627  22.14341
##    3.906939937  30.03922  0.7749865  22.77972
##    4.714866363  31.07975  0.7624156  23.61664
##    5.689866029  32.49155  0.7432479  24.79807
##    6.866488450  34.12505  0.7195348  26.18933
##    8.286427729  35.58811  0.7005186  27.46582
##   10.000000000  37.47108  0.6724139  29.08059
## 
## Tuning parameter 'alpha' was held constant at a value of 1
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were alpha = 1 and lambda = 0.01676833.
```

---


```r
mod_rf
```

```
## Random Forest 
## 
## 19230 samples
##    12 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 15384, 15384, 15384, 15385, 15383 
## Resampling results across tuning parameters:
## 
##   min.node.size  mtry  RMSE      Rsquared   MAE     
##   10              2    44.46119  0.7126922  35.75270
##   10              4    33.22558  0.7903895  26.03864
##   10              6    28.34899  0.8210037  21.87503
##   10              8    25.75484  0.8373422  19.74784
##   10             10    24.59800  0.8445753  18.76416
##   20              2    44.12560  0.7140751  35.35874
##   20              4    33.38484  0.7892705  26.15563
##   20              6    28.76182  0.8186550  22.23829
##   20              8    25.71983  0.8371620  19.72128
##   20             10    24.63315  0.8440852  18.80395
##   30              2    43.48024  0.7332561  34.84502
##   30              4    34.31972  0.7807501  26.94342
##   30              6    28.61490  0.8192508  22.10767
##   30              8    25.83251  0.8365044  19.80986
##   30             10    24.74613  0.8434765  18.90919
## 
## Tuning parameter 'splitrule' was held constant at a value of variance
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were mtry = 10, splitrule =
##  variance and min.node.size = 10.
```

---


```r
plot(mod_ridge)
```

&lt;img src="images/Ridge-CV-1.png" width="80%" /&gt;

---


```r
plot(mod_lasso)
```

&lt;img src="images/Lasso-CV-1.png" width="80%" /&gt;

---


```r
plot(mod_rf)
```

&lt;img src="images/RF-CV-1.png" width="80%" /&gt;

---

### Comparing Models


```r
resamps &lt;- resamples(list(Ridge = mod_ridge,
                          Lasso = mod_lasso,
                          RF = mod_rf))
summary(resamps)
```

```
## 
## Call:
## summary.resamples(object = resamps)
## 
## Models: Ridge, Lasso, RF 
## Number of resamples: 5 
## 
## MAE 
##           Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's
## Ridge 20.21697 20.40482 20.47514 20.47454 20.60721 20.66855    0
## Lasso 20.03314 20.08440 20.11722 20.18166 20.19072 20.48283    0
## RF    18.33264 18.57500 18.64885 18.76416 19.00912 19.25519    0
## 
## RMSE 
##           Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's
## Ridge 26.59173 26.63820 26.80070 26.82721 26.96887 27.13656    0
## Lasso 26.21031 26.36819 26.36904 26.40433 26.43962 26.63447    0
## RF    24.21951 24.29361 24.44555 24.59800 24.88725 25.14407    0
## 
## Rsquared 
##            Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## Ridge 0.8064264 0.8092651 0.8108918 0.8110942 0.8144137 0.8144736    0
## Lasso 0.8115983 0.8120177 0.8125692 0.8151910 0.8193738 0.8203960    0
## RF    0.8397498 0.8416926 0.8434941 0.8445753 0.8478330 0.8501068    0
```

---


```r
dotplot(resamps, metric = "RMSE")
```

&lt;img src="images/Caret-RMSE-Comp-1.png" width="100%" /&gt;

---

### Predicting


```r
pred_ridge &lt;- predict(mod_ridge, newdata = ipf_te)
pred_lasso &lt;- predict(mod_lasso, newdata = ipf_te)
pred_rf &lt;- predict(mod_rf, newdata = ipf_te)

rmse_ridge &lt;- RMSE(pred_ridge, ipf_te$best3bench_kg)
rmse_lasso &lt;- RMSE(pred_lasso, ipf_te$best3bench_kg)
rmse_rf &lt;- RMSE(pred_rf, ipf_te$best3bench_kg)

glue("Test RMSE Ridge: {format(rmse_ridge, digits = 3)}
     Test RMSE Lassoe: {format(rmse_lasso, digits = 3)}
     Test RMSE RF: {format(rmse_rf, digits = 3)}")
```

```
## Test RMSE Ridge: 26.5
## Test RMSE Lassoe: 26
## Test RMSE RF: 24.3
```

.warning[
⚠️ Is using a "regular" regression model the natural approach for these data?

Ask yourself what is this model good for, if at all 😮
]

---


```r
bind_rows(
  tibble(method = "Ridge", pred = pred_ridge, true = ipf_te$best3bench_kg),
  tibble(method = "Lasso", pred = pred_lasso, true = ipf_te$best3bench_kg),
  tibble(method = "RF", pred = pred_rf, true = ipf_te$best3bench_kg)) %&gt;%
  ggplot(aes(pred, true)) +
  geom_point(color = "red", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0) +
  facet_wrap(~ method) +
  theme_bw()
```

&lt;img src="images/Caret-Pred-vs-True-1.png" width="100%" /&gt;

---

class: section-slide

# The Future Solution: `tidymodels`

#### Inspired by [Julia Silge](https://juliasilge.com/blog/intro-tidymodels/)

---

### Packages under tidymodels

- `paresnip`: tidy `caret`
- `dials` and `tune`: specifying and tuning model parameters
- `rsample`: sampling, data partitioning
- `recipes` and `embed`: preprocessing and creating model matrices
- `infer`: tidy statistics
- `yardstick`: measuring models performance
- `broom`: convert models output into tidy tibbles

And [more](https://www.tidyverse.org/blog/2018/08/tidymodels-0-0-1/).

.warning[
⚠️ All `tidymodels` packages are under development!
]

---

### Split Data

The `initial_split()` function is from the `rsample` package:


```r
library(tidymodels)

ipf_split_obj &lt;- ipf_lifts %&gt;%
  initial_split(prop = 0.6, strata = equipment)

ipf_tr &lt;- training(ipf_split_obj)
ipf_te &lt;- testing(ipf_split_obj)

glue("train no. of rows: {nrow(ipf_tr)}
     test no. of rows: {nrow(ipf_te)}")
```

```
## train no. of rows: 19229
## test no. of rows: 12818
```

```r
print(ipf_split_obj)
```

```
## &lt;19229/12818/32047&gt;
```

---

### Preprocess .font80percent[(but we're not gonna use it)]

The `recipe()` function is from the `recipes` package. It allows you to specify a python-like pipe you can later apply to any dataset, including all preprocessing steps:


```r
ipf_rec &lt;- recipe(best3bench_kg ~ ., data = ipf_tr)
ipf_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         12
```

`recipes` contains more preprocessing `step_`s than you imagine:


```r
ipf_rec &lt;-  ipf_rec %&gt;%
  step_normalize(all_numeric())
```

---

After you have your `recipe` you need to `prep()` materials...


```r
ipf_rec &lt;- ipf_rec %&gt;% prep(ipf_tr)

ipf_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         12
## 
## Training data contained 19229 data points and no missing data.
## 
## Operations:
## 
## Centering and scaling for age, bodyweight_kg, year, month, ... [trained]
```

At this point our `recipe` has all necessary `sd` and `mean`s for numeric variables.

---

And then we `bake()`:


```r
ipf_tr2 &lt;- ipf_rec %&gt;% bake(ipf_tr)
ipf_te2 &lt;- ipf_rec %&gt;% bake(ipf_te)

glue("mean of age in orig training: {format(mean(ipf_tr$age), digits = 3)}, sd: {format(sd(ipf_tr$age), digits = 3)}
     mean of age in baked training: {format(mean(ipf_tr2$age), digits = 0)}, sd: {format(sd(ipf_tr2$age), digits = 3)}")
```

```
## mean of age in orig training: 36.6, sd: 14.3
## mean of age in baked training: 0, sd: 1
```

```r
glue("mean of age in orig testing: {format(mean(ipf_te$age), digits = 3)}, sd: {format(sd(ipf_te$age), digits = 3)}
     mean of age in baked testing: {format(mean(ipf_te2$age), digits = 0)}, sd: {format(sd(ipf_te2$age), digits = 3)}")
```

```
## mean of age in orig testing: 36.7, sd: 14.2
## mean of age in baked testing: 0, sd: 0.994
```

---

Or you can do it all in a single pipe:


```r
ipf_rec &lt;- recipe(best3bench_kg ~ ., data = ipf_tr) %&gt;%
  step_normalize(all_numeric()) %&gt;%
  prep(ipf_tr)

ipf_tr2 &lt;- ipf_rec %&gt;% bake(ipf_tr)
ipf_te2 &lt;- ipf_rec %&gt;% bake(ipf_te)

glue("mean of age in orig training: {format(mean(ipf_tr$age), digits = 3)}, sd: {format(sd(ipf_tr$age), digits = 3)}
     mean of age in baked training: {format(mean(ipf_tr2$age), digits = 0)}, sd: {format(sd(ipf_tr2$age), digits = 2)}")
```

```
## mean of age in orig training: 36.6, sd: 14.3
## mean of age in baked training: 0, sd: 1
```

```r
glue("mean of age in orig testing: {format(mean(ipf_te$age), digits = 3)}, sd: {format(sd(ipf_te$age), digits = 3)}
     mean of age in baked testing: {format(mean(ipf_te2$age), digits = 0)}, sd: {format(sd(ipf_te2$age), digits = 3)}")
```

```
## mean of age in orig testing: 36.7, sd: 14.2
## mean of age in baked testing: 0, sd: 0.994
```

---

### Modeling

For now let us use the original `ipf_tr` data.

Functions `linear_reg()` and `set_engine()` are from the `parsnip` package:


```r
mod_ridge_spec &lt;- linear_reg(mixture = 0, penalty = 0.001) %&gt;%
  set_engine(engine = "glmnet")

mod_ridge_spec
```

```
## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 0.001
##   mixture = 0
## 
## Computational engine: glmnet
```

---


```r
mod_ridge &lt;- mod_ridge_spec %&gt;%
  fit(best3bench_kg ~ ., data = ipf_tr)

mod_ridge
```

```
## parsnip model object
## 
## Fit in:  51ms
## Call:  glmnet::glmnet(x = as.matrix(x), y = y, family = "gaussian",      alpha = ~0) 
## 
##     Df    %Dev Lambda
## 1   51 0.00000  43490
## 2   51 0.00396  39620
## 3   51 0.00435  36100
## 4   51 0.00477  32900
## 5   51 0.00523  29970
## 6   51 0.00574  27310
## 7   51 0.00629  24880
## 8   51 0.00690  22670
## 9   51 0.00757  20660
## 10  51 0.00830  18820
## 11  51 0.00910  17150
## 12  51 0.00998  15630
## 13  51 0.01094  14240
## 14  51 0.01200  12980
## 15  51 0.01315  11820
## 16  51 0.01442  10770
## 17  51 0.01580   9815
## 18  51 0.01731   8943
## 19  51 0.01897   8149
## 20  51 0.02078   7425
## 21  51 0.02276   6765
## 22  51 0.02492   6164
## 23  51 0.02728   5617
## 24  51 0.02986   5118
## 25  51 0.03267   4663
## 26  51 0.03574   4249
## 27  51 0.03909   3871
## 28  51 0.04273   3527
## 29  51 0.04670   3214
## 30  51 0.05102   2928
## 31  51 0.05571   2668
## 32  51 0.06081   2431
## 33  51 0.06633   2215
## 34  51 0.07233   2018
## 35  51 0.07881   1839
## 36  51 0.08582   1676
## 37  51 0.09339   1527
## 38  51 0.10160   1391
## 39  51 0.11030   1268
## 40  51 0.11980   1155
## 41  51 0.12990   1052
## 42  51 0.14070    959
## 43  51 0.15230    874
## 44  51 0.16460    796
## 45  51 0.17780    725
## 46  51 0.19170    661
## 47  51 0.20640    602
## 48  51 0.22190    549
## 49  51 0.23820    500
## 50  51 0.25520    456
## 51  51 0.27310    415
## 52  51 0.29160    378
## 53  51 0.31080    345
## 54  51 0.33050    314
## 55  51 0.35090    286
## 56  51 0.37160    261
## 57  51 0.39280    238
## 58  51 0.41410    216
## 59  51 0.43570    197
## 60  51 0.45730    180
## 61  51 0.47880    164
## 62  51 0.50010    149
## 63  51 0.52120    136
## 64  51 0.54180    124
## 65  51 0.56190    113
## 66  51 0.58140    103
## 67  51 0.60010     94
## 68  51 0.61810     85
## 69  51 0.63520     78
## 70  51 0.65140     71
## 71  51 0.66670     65
## 72  51 0.68100     59
## 73  51 0.69430     54
## 74  51 0.70670     49
## 75  51 0.71810     45
## 76  51 0.72850     41
## 77  51 0.73800     37
## 78  51 0.74670     34
## 79  51 0.75450     31
## 80  51 0.76160     28
## 81  51 0.76800     25
## 82  51 0.77360     23
## 83  51 0.77870     21
## 84  51 0.78320     19
## 85  51 0.78720     18
## 86  51 0.79070     16
## 87  51 0.79380     15
## 88  51 0.79650     13
## 89  51 0.79890     12
## 90  51 0.80100     11
## 91  51 0.80290     10
## 92  51 0.80450      9
## 93  51 0.80590      8
## 94  51 0.80720      8
## 95  51 0.80830      7
## 96  51 0.80920      6
## 97  51 0.81010      6
## 98  51 0.81080      5
## 99  51 0.81150      5
## 100 51 0.81200      4
```

---

In a single pipe:


```r
mod_lasso &lt;- linear_reg(mixture = 1, penalty = 0.001) %&gt;%
  set_engine(engine = "glmnet") %&gt;%
  fit(best3bench_kg ~ ., data = ipf_tr)

mod_lasso
```

```
## parsnip model object
## 
## Fit in:  61ms
## Call:  glmnet::glmnet(x = as.matrix(x), y = y, family = "gaussian",      alpha = ~1) 
## 
##    Df    %Dev Lambda
## 1   0 0.00000 43.490
## 2   1 0.08583 39.620
## 3   2 0.15840 36.100
## 4   2 0.23960 32.900
## 5   2 0.30710 29.970
## 6   2 0.36310 27.310
## 7   2 0.40960 24.880
## 8   2 0.44820 22.670
## 9   2 0.48030 20.660
## 10  2 0.50690 18.820
## 11  2 0.52900 17.150
## 12  2 0.54730 15.630
## 13  2 0.56250 14.240
## 14  2 0.57520 12.980
## 15  4 0.59060 11.820
## 16  4 0.61240 10.770
## 17  6 0.63380  9.815
## 18  6 0.65320  8.943
## 19  6 0.66930  8.149
## 20  6 0.68260  7.425
## 21  7 0.69540  6.765
## 22  8 0.70750  6.164
## 23  8 0.72280  5.617
## 24  8 0.73560  5.118
## 25  9 0.74630  4.663
## 26  9 0.75510  4.249
## 27 10 0.76290  3.871
## 28 11 0.77000  3.527
## 29 11 0.77590  3.214
## 30 12 0.78130  2.928
## 31 13 0.78570  2.668
## 32 14 0.78980  2.431
## 33 14 0.79310  2.215
## 34 15 0.79590  2.018
## 35 15 0.79840  1.839
## 36 17 0.80060  1.676
## 37 18 0.80260  1.527
## 38 18 0.80440  1.391
## 39 18 0.80580  1.268
## 40 18 0.80700  1.155
## 41 18 0.80810  1.052
## 42 19 0.80890  0.959
## 43 21 0.80970  0.874
## 44 21 0.81030  0.796
## 45 22 0.81090  0.725
## 46 24 0.81150  0.661
## 47 27 0.81200  0.602
## 48 27 0.81240  0.549
## 49 27 0.81280  0.500
## 50 29 0.81310  0.456
## 51 30 0.81340  0.415
## 52 31 0.81370  0.378
## 53 33 0.81390  0.345
## 54 33 0.81400  0.314
## 55 33 0.81420  0.286
## 56 36 0.81430  0.261
## 57 37 0.81440  0.238
## 58 37 0.81450  0.216
## 59 39 0.81460  0.197
## 60 41 0.81470  0.180
## 61 41 0.81500  0.164
## 62 41 0.81550  0.149
## 63 41 0.81580  0.136
## 64 44 0.81610  0.124
## 65 43 0.81640  0.113
## 66 44 0.81670  0.103
## 67 45 0.81690  0.094
## 68 45 0.81710  0.085
## 69 46 0.81720  0.078
## 70 49 0.81730  0.071
## 71 50 0.81750  0.065
## 72 48 0.81770  0.059
## 73 48 0.81780  0.054
## 74 48 0.81780  0.049
## 75 48 0.81790  0.045
## 76 48 0.81800  0.041
## 77 49 0.81800  0.037
## 78 49 0.81810  0.034
## 79 49 0.81810  0.031
## 80 49 0.81820  0.028
## 81 49 0.81820  0.025
## 82 49 0.81820  0.023
```

---

Can also use `fit_xy()` a-la `sklearn`:


```r
mod_rf &lt;- rand_forest(mode = "regression", mtry = 4, trees = 50, min_n = 30) %&gt;%
  set_engine("ranger") %&gt;%
  fit_xy(x = ipf_tr[, -7],
         y = ipf_tr$best3bench_kg)

mod_rf
```

```
## parsnip model object
## 
## Fit in:  671msRanger result
## 
## Call:
##  ranger::ranger(formula = formula, data = data, mtry = ~4, num.trees = ~50,      min.node.size = ~30, num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) 
## 
## Type:                             Regression 
## Number of trees:                  50 
## Sample size:                      19229 
## Number of independent variables:  12 
## Mtry:                             4 
## Target node size:                 30 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       561.2796 
## R squared (OOB):                  0.8499749
```

---

Notice how easy it is to get the model's results in a tidy way using the `tidy()` function:


```r
tidy(mod_ridge)
```

```
## # A tibble: 5,200 x 5
##    term                 step  estimate lambda dev.ratio
##    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;
##  1 (Intercept)             1  1.49e+ 2 43487.  2.60e-36
##  2 sexM                    1  8.48e-35 43487.  2.60e-36
##  3 eventSB                 1 -8.72e-36 43487.  2.60e-36
##  4 eventSBD                1 -2.38e-35 43487.  2.60e-36
##  5 equipmentSingle-ply     1  2.96e-35 43487.  2.60e-36
##  6 age                     1 -5.60e-37 43487.  2.60e-36
##  7 divisionJuniors         1 -5.27e-36 43487.  2.60e-36
##  8 divisionLight           1 -2.22e-35 43487.  2.60e-36
##  9 divisionMasters 1       1 -1.59e-36 43487.  2.60e-36
## 10 divisionMasters 2       1 -1.53e-35 43487.  2.60e-36
## # ... with 5,190 more rows
```

---

### Predicting


```r
results_test &lt;- mod_ridge %&gt;%
  predict(new_data = ipf_te, penalty = 0.001) %&gt;%
  mutate(
    truth = ipf_te$best3bench_kg,
    method = "Ridge"
  ) %&gt;%
  bind_rows(mod_lasso %&gt;%
    predict(new_data = ipf_te) %&gt;%
    mutate(
      truth = ipf_te$best3bench_kg,
      method = "Lasso"
  )) %&gt;%
  bind_rows(mod_rf %&gt;%
    predict(new_data = ipf_te) %&gt;%
    mutate(
      truth = ipf_te$best3bench_kg,
      method = "RF"
  ))

dim(results_test)
```

```
## [1] 38454     3
```

---

### Comparing Models

The package `yardstick` has tons of performance metrics:


```r
results_test %&gt;%
  group_by(method) %&gt;%
  yardstick::rmse(truth = truth, estimate = .pred)
```

```
## # A tibble: 3 x 4
##   method .metric .estimator .estimate
##   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 Lasso  rmse    standard        26.4
## 2 RF     rmse    standard        23.8
## 3 Ridge  rmse    standard        26.9
```

---


```r
results_test %&gt;%
  ggplot(aes(.pred, truth)) +
  geom_point(color = "red", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0) +
  facet_wrap(~ method) +
  theme_bw()
```

&lt;img src="images/Tidymodels-Pred-vs-True-1.png" width="100%" /&gt;

---

### Tuning

This isn't completely clear to me, but it seems to work:

Define your model spec, using `tune()` from the `tune` package (needs to be installed separately) for a paramter you wish to tune:


```r
library(tune)

mod_rf_spec &lt;- rand_forest(mode = "regression",
                           mtry = tune("mtry"),
                           min_n = tune("min_n")) %&gt;%
  set_engine("ranger")
```

---

Define the `grid` on which you train your params, with the `dials` package:


```r
rf_grid &lt;- grid_regular(mtry(range(2, 10)), min_n(range(10, 30)),
                        levels = c(5, 3))

rf_grid
```

```
## # A tibble: 15 x 2
##     mtry min_n
##    &lt;int&gt; &lt;int&gt;
##  1     2    10
##  2     4    10
##  3     6    10
##  4     8    10
##  5    10    10
##  6     2    20
##  7     4    20
##  8     6    20
##  9     8    20
## 10    10    20
## 11     2    30
## 12     4    30
## 13     6    30
## 14     8    30
## 15    10    30
```

---

Split your data into a few folds for Cross Validation with `vfold_cv()` from the `rsample` package:


```r
cv_splits &lt;- vfold_cv(ipf_tr, v = 5)

cv_splits
```

```
## #  5-fold cross-validation 
## # A tibble: 5 x 2
##   splits               id   
##   &lt;named list&gt;         &lt;chr&gt;
## 1 &lt;split [15.4K/3.8K]&gt; Fold1
## 2 &lt;split [15.4K/3.8K]&gt; Fold2
## 3 &lt;split [15.4K/3.8K]&gt; Fold3
## 4 &lt;split [15.4K/3.8K]&gt; Fold4
## 5 &lt;split [15.4K/3.8K]&gt; Fold5
```

---

Now perform cross validation with `tune_grid()` from the `tune` package:


```r
tune_res &lt;- tune_grid(recipe(best3bench_kg ~ ., data = ipf_tr),
                      model = mod_rf_spec,
                      resamples = cv_splits,
                      grid = rf_grid,
                      metrics = metric_set(rmse))
tune_res
```


```
## #  5-fold cross-validation 
## # A tibble: 5 x 4
##   splits               id    .metrics          .notes          
## * &lt;list&gt;               &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
## 1 &lt;split [15.4K/3.8K]&gt; Fold1 &lt;tibble [15 x 5]&gt; &lt;tibble [0 x 1]&gt;
## 2 &lt;split [15.4K/3.8K]&gt; Fold2 &lt;tibble [15 x 5]&gt; &lt;tibble [0 x 1]&gt;
## 3 &lt;split [15.4K/3.8K]&gt; Fold3 &lt;tibble [15 x 5]&gt; &lt;tibble [0 x 1]&gt;
## 4 &lt;split [15.4K/3.8K]&gt; Fold4 &lt;tibble [15 x 5]&gt; &lt;tibble [0 x 1]&gt;
## 5 &lt;split [15.4K/3.8K]&gt; Fold5 &lt;tibble [15 x 5]&gt; &lt;tibble [0 x 1]&gt;
```

---

Collect the mean metric across folds:


```r
estimates &lt;- collect_metrics(tune_res)

estimates
```

```
## # A tibble: 15 x 7
##     mtry min_n .metric .estimator  mean     n std_err
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
##  1     2    10 rmse    standard    24.7     5   0.197
##  2     2    20 rmse    standard    24.7     5   0.190
##  3     2    30 rmse    standard    24.8     5   0.192
##  4     4    10 rmse    standard    23.7     5   0.186
##  5     4    20 rmse    standard    23.6     5   0.192
##  6     4    30 rmse    standard    23.5     5   0.181
##  7     6    10 rmse    standard    23.9     5   0.191
##  8     6    20 rmse    standard    23.7     5   0.186
##  9     6    30 rmse    standard    23.6     5   0.186
## 10     8    10 rmse    standard    24.0     5   0.203
## 11     8    20 rmse    standard    23.7     5   0.185
## 12     8    30 rmse    standard    23.6     5   0.185
## 13    10    10 rmse    standard    24.1     5   0.206
## 14    10    20 rmse    standard    23.8     5   0.181
## 15    10    30 rmse    standard    23.7     5   0.183
```

---

Choose best paramter:


```r
estimates %&gt;%
  mutate(min_n = factor(min_n)) %&gt;%
  ggplot(aes(x = mtry, y = mean, color = min_n)) + 
  geom_point() + 
  geom_line() + 
  labs(y = "Mean RMSE") +
  theme_classic()
```

&lt;img src="images/Tidymodels-RMSE-Comp-1.png" width="100%" /&gt;

---

class: section-slide

# `infer`: Tidy Statistics

---

### Statistical Q1

Is there a relation between men and women and the type of equipment they use in 2019? Assume observations are independent.


```r
sex_vs_equipment &lt;- ipf_lifts %&gt;%
  filter(year == 2019) %&gt;%
  select(sex, equipment) %&gt;%
  table()

sex_vs_equipment
```

```
##    equipment
## sex Raw Single-ply
##   F 678        186
##   M 854        287
```


```r
prop.table(sex_vs_equipment, margin = 1)
```

```
##    equipment
## sex       Raw Single-ply
##   F 0.7847222  0.2152778
##   M 0.7484663  0.2515337
```

---

### Statistical Q2

Is there a difference between men and women age in 2019? Assume observations are independent.


```r
ipf_lifts %&gt;%
  filter(year == 2019) %&gt;%
  group_by(sex) %&gt;% summarise(avg = mean(age), sd = sd(age), n = n())
```

```
## # A tibble: 2 x 4
##   sex     avg    sd     n
##   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1 F      36.0  15.5   864
## 2 M      38.8  16.7  1141
```

---

### Same Problem!

Varied interface, varied output.


```r
prop.test(sex_vs_equipment[,1], rowSums(sex_vs_equipment))
```

```
## 
## 	2-sample test for equality of proportions with continuity
## 	correction
## 
## data:  sex_vs_equipment[, 1] out of rowSums(sex_vs_equipment)
## X-squared = 3.3872, df = 1, p-value = 0.0657
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.001975717  0.074487646
## sample estimates:
##    prop 1    prop 2 
## 0.7847222 0.7484663
```

---


```r
t.test(age ~ sex, data = ipf_lifts %&gt;% filter(year == 2019))
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  age by sex
## t = -3.8797, df = 1921.8, p-value = 0.0001081
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -4.228319 -1.388844
## sample estimates:
## mean in group F mean in group M 
##        35.97801        38.78659
```

---

### The `generics::tidy()` Approach

(Also available when you load several other packages, like `broom` and `yardstick`)


```r
tidy(prop.test(sex_vs_equipment[,1], rowSums(sex_vs_equipment)))
```

```
## # A tibble: 1 x 9
##   estimate1 estimate2 statistic p.value parameter conf.low conf.high method
##       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; 
## 1     0.785     0.748      3.39  0.0657         1 -0.00198    0.0745 2-sam~
## # ... with 1 more variable: alternative &lt;chr&gt;
```


```r
tidy(t.test(age ~ sex, data = ipf_lifts %&gt;% filter(year == 2019)))
```

```
## # A tibble: 1 x 10
##   estimate estimate1 estimate2 statistic p.value parameter conf.low
##      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1    -2.81      36.0      38.8     -3.88 1.08e-4     1922.    -4.23
## # ... with 3 more variables: conf.high &lt;dbl&gt;, method &lt;chr&gt;,
## #   alternative &lt;chr&gt;
```

---

### The `infer` Approach

&gt; infer implements an expressive grammar to perform statistical inference that coheres with the tidyverse design framework

4 main verbs for a typical flow:

* `specify()` - dependent/independent variables, formula
* `hypothesize()` - declare the null hypothesis
* `generate()` - generate data reflecting the null hypothesis (the permutation/bootstrap approach)
* `calculate()` - calculate a distribution of statistics from the generated data, from which you can extract conclusion based on a p-value for example

---

### `infer` Diff in Proportions Test

Get the observed statistic (here manually in order to not confuse you, there *is* a way via `infer`):


```r
#    equipment
# sex Raw Single-ply
#   F 678        186
#   M 854        287
p_F &lt;- sex_vs_equipment[1, 1] / (sum(sex_vs_equipment[1, ]))
p_M &lt;- sex_vs_equipment[2, 1] / (sum(sex_vs_equipment[2, ]))
obs_diff &lt;- p_F - p_M
obs_diff
```

```
## [1] 0.03625596
```

---

Get distribution of the difference in proportions under null hypothesis


```r
diff_null_perm &lt;- ipf_lifts %&gt;%
  filter(year == 2019) %&gt;%
  specify(equipment ~ sex, success = "Raw") %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 200, type = "permute") %&gt;%
  calculate(stat = "diff in props", order = c("F", "M"))

diff_null_perm
```

```
## # A tibble: 200 x 2
##    replicate     stat
##        &lt;int&gt;    &lt;dbl&gt;
##  1         1 -0.0126 
##  2         2 -0.00645
##  3         3  0.0200 
##  4         4 -0.0492 
##  5         5 -0.0248 
##  6         6  0.00168
##  7         7  0.0200 
##  8         8 -0.00442
##  9         9 -0.00645
## 10        10  0.00168
## # ... with 190 more rows
```

---

Visualize the permuted difference null distribution and the p-value


```r
visualize(diff_null_perm) +
  shade_p_value(obs_stat = obs_diff, direction = "two_sided")
```

&lt;img src="images/Diff-in-Props-Null-1.png" width="50%" /&gt;

---

Get the actual p-value:


```r
diff_null_perm %&gt;% 
  get_p_value(obs_stat = obs_diff, direction = "two_sided")
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1    0.07
```

---

### `infer` t Test (independent samples)

Get the observed statistic (here via `infer`):


```r
obs_t &lt;- ipf_lifts %&gt;%
  filter(year == 2019) %&gt;%
  specify(age ~ sex) %&gt;%
  calculate(stat = "t", order = c("F", "M"))
obs_t
```

```
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1 -3.88
```


---

Get distribution of the t statistic under null hypothesis


```r
t_null_perm &lt;- ipf_lifts %&gt;%
  filter(year == 2019) %&gt;%
  specify(age ~ sex) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 100, type = "permute") %&gt;%
  calculate(stat = "t", order = c("F", "M"))

t_null_perm
```

```
## # A tibble: 100 x 2
##    replicate    stat
##        &lt;int&gt;   &lt;dbl&gt;
##  1         1 -0.450 
##  2         2 -0.268 
##  3         3  1.20  
##  4         4  1.14  
##  5         5  1.04  
##  6         6  0.0967
##  7         7  0.908 
##  8         8  0.456 
##  9         9 -0.758 
## 10        10 -0.575 
## # ... with 90 more rows
```

---

Visualize the permuted t statistic null distribution and the two-sided p-value


```r
visualize(t_null_perm) +
  shade_p_value(obs_stat = obs_t, direction = "two_sided")
```

&lt;img src="images/T-Null-1.png" width="50%" /&gt;

---

Get the actual p-value:


```r
t_null_perm %&gt;% 
  get_p_value(obs_stat = obs_t, direction = "two_sided")
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="../libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
